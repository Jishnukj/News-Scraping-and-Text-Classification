{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import punkt\n",
    "from nltk.corpus.reader import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table\n",
    "import dash_renderer\n",
    "from dash.dependencies import Input, Output, State\n",
    "import plotly.graph_objs as go\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_models =  r\"Y:\\project\"\n",
    "path_svm = path_models + 'best_svc.pickle'\n",
    "with open(path_svm, 'rb') as data:\n",
    "    svc_model = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tfidf = r\"Y:\\project\\tfidf.pickle\"\n",
    "\n",
    "with open(path_tfidf, 'rb') as data:\n",
    "    tfidf = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_codes = {\n",
    "    'business': 0,\n",
    "    'entertainment': 1,\n",
    "    'politics': 2,\n",
    "    'sport': 3,\n",
    "    'tech': 4,\n",
    "    'other':5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_dailymail():\n",
    "\n",
    "    \n",
    "    url = \"https://www.dailymail.co.uk\"\n",
    "    \n",
    "  \n",
    "    r1 = requests.get(url)\n",
    "    r1.status_code\n",
    "\n",
    "    \n",
    "    coverpage = r1.content\n",
    "\n",
    "    \n",
    "    soup1 = BeautifulSoup(coverpage, 'html5lib')\n",
    "\n",
    "    \n",
    "    coverpage_news = soup1.find_all('h2', class_='linkro-darkred')\n",
    "    len(coverpage_news)\n",
    "    \n",
    "    number_of_articles = 4\n",
    "\n",
    "    \n",
    "    news_contents = []\n",
    "    list_links = []\n",
    "    list_titles = []\n",
    "\n",
    "    for n in np.arange(0, number_of_articles):\n",
    "\n",
    "        \n",
    "        link = url + coverpage_news[n].find('a')['href']\n",
    "        list_links.append(link)\n",
    "\n",
    "        \n",
    "        title = coverpage_news[n].find('a').get_text()\n",
    "        list_titles.append(title)\n",
    "\n",
    "        \n",
    "        article = requests.get(link)\n",
    "        article_content = article.content\n",
    "        soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "        body = soup_article.find_all('p', class_='mol-para-with-font')\n",
    "\n",
    "        \n",
    "        list_paragraphs = []\n",
    "        for p in np.arange(0, len(body)):\n",
    "            paragraph = body[p].get_text()\n",
    "            list_paragraphs.append(paragraph)\n",
    "            final_article = \" \".join(list_paragraphs)\n",
    "\n",
    "        \n",
    "        final_article = re.sub(\"\\\\xa0\", \"\", final_article)\n",
    "        \n",
    "        news_contents.append(final_article)\n",
    "        \n",
    "\n",
    "   \n",
    "    df_features = pd.DataFrame(\n",
    "         {'Content': news_contents \n",
    "        })\n",
    "\n",
    "    \n",
    "    df_show_info = pd.DataFrame(\n",
    "        {'Article Title': list_titles,\n",
    "         'Article Link': list_links,\n",
    "         'Newspaper': 'Daily Mail'})\n",
    "    \n",
    "    return (df_features, df_show_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_theguardian():\n",
    "    \n",
    "    \n",
    "    url = \"https://www.theguardian.com/uk\"\n",
    "    \n",
    "   \n",
    "    r1 = requests.get(url)\n",
    "    r1.status_code\n",
    "\n",
    "    \n",
    "    coverpage = r1.content\n",
    "\n",
    "    \n",
    "    soup1 = BeautifulSoup(coverpage, 'html5lib')\n",
    "\n",
    "    \n",
    "    coverpage_news = soup1.find_all('h3', class_='fc-item__title')\n",
    "    len(coverpage_news)\n",
    "    \n",
    "    number_of_articles = 10\n",
    "\n",
    "    \n",
    "    news_contents = []\n",
    "    list_links = []\n",
    "    list_titles = []\n",
    "\n",
    "    for n in np.arange(0, number_of_articles,2):\n",
    "\n",
    "        \n",
    "        if \"live\" in coverpage_news[n].find('a')['href']:  \n",
    "            continue\n",
    "\n",
    "       \n",
    "        link = coverpage_news[n].find('a')['href']\n",
    "        list_links.append(link)\n",
    "\n",
    "       \n",
    "        title = coverpage_news[n].find('a').get_text()\n",
    "        list_titles.append(title)\n",
    "\n",
    "        \n",
    "        article = requests.get(link)\n",
    "        article_content = article.content\n",
    "        soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "        body = soup_article.find_all('div', class_='content__article-body from-content-api js-article__body')\n",
    "        x = body[0].find_all('p')\n",
    "\n",
    "    \n",
    "        list_paragraphs = []\n",
    "        for p in np.arange(0, len(x)):\n",
    "            paragraph = x[p].get_text()\n",
    "            list_paragraphs.append(paragraph)\n",
    "            final_article = \" \".join(list_paragraphs)\n",
    "\n",
    "        news_contents.append(final_article)\n",
    "\n",
    "    \n",
    "    df_features = pd.DataFrame(\n",
    "         {'Content': news_contents \n",
    "        })\n",
    "\n",
    "\n",
    "    df_show_info = pd.DataFrame(\n",
    "        {'Article Title': list_titles,\n",
    "         'Article Link': list_links,\n",
    "         'Newspaper': 'The Guardian'})\n",
    "\n",
    "    \n",
    "    return (df_features, df_show_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = list(\"?:!.,;\")\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "def create_features_from_df(df):\n",
    "    \n",
    "    df['Content_Parsed_1'] = df['Content'].str.replace(\"\\r\", \" \")\n",
    "    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n",
    "    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")\n",
    "    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')\n",
    "    \n",
    "    df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower()\n",
    "    \n",
    "    df['Content_Parsed_3'] = df['Content_Parsed_2']\n",
    "    for punct_sign in punctuation_signs:\n",
    "        df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')\n",
    "        \n",
    "    df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")\n",
    "    \n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    nrows = len(df)\n",
    "    lemmatized_text_list = []\n",
    "    for row in range(0, nrows):\n",
    "\n",
    "        \n",
    "        lemmatized_list = []     \n",
    "        text = df.loc[row]['Content_Parsed_4']\n",
    "        text_words = text.split(\" \")\n",
    "        \n",
    "        for word in text_words:\n",
    "            lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        lemmatized_text = \" \".join(lemmatized_list)\n",
    "        lemmatized_text_list.append(lemmatized_text)\n",
    "    \n",
    "    df['Content_Parsed_5'] = lemmatized_text_list   \n",
    "    df['Content_Parsed_6'] = df['Content_Parsed_5']\n",
    "    for stop_word in stop_words:\n",
    "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "        df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')\n",
    "        \n",
    "    df = df['Content_Parsed_6']\n",
    "    df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})\n",
    "    \n",
    "\n",
    "    features = tfidf.transform(df).toarray()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_name(category_id):\n",
    "    for category, id_ in category_codes.items():    \n",
    "        if id_ == category_id:\n",
    "            return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_from_features(features):\n",
    "        \n",
    "\n",
    "    predictions_proba = svc_model.predict_proba(features).max(axis=1)    \n",
    "    \n",
    "\n",
    "    predictions_pre = svc_model.predict(features)\n",
    "\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for prob, cat in zip(predictions_proba, predictions_pre):\n",
    "        if prob > .65:\n",
    "            predictions.append(cat)\n",
    "        else:\n",
    "            predictions.append(5)\n",
    "\n",
    "\n",
    "    categories = [get_category_name(x) for x in predictions]\n",
    "    \n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complete_df(df, categories):\n",
    "    df['Prediction'] = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "colors = {\n",
    "    'background': '#ECECEC',  \n",
    "    'text': '#696969',\n",
    "    'titles': '#599ACF',\n",
    "    'blocks': '#F7F7F7',\n",
    "    'graph_background': '#F7F7F7',\n",
    "    'banner': '#C3DCF2'\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "markdown_text1 = '''\n",
    "\n",
    "This application gathers the latest news from the newspapers  **The Guardian** and **Daily Mail**, predicts their category between **Politics**, **Business**, **Entertainment**, **Sport**, **Tech** and **Other** and then shows a summary.\n",
    "\n",
    "The scraped news are converted into a numeric feature vector with *TF-IDF vectorization*. Then, a *Support Vector Classifier* is applied to predict each category.\n",
    "\n",
    "This app is meant for didactic purposes.\n",
    "\n",
    "Please enter which newspapers would you like to scrape news off and press the **Scrape** button.\n",
    "\n",
    "'''\n",
    "\n",
    "markdown_text2 = \"\"\n",
    "app.layout = html.Div(style={'backgroundColor':colors['background']}, children=[\n",
    "    \n",
    "\n",
    "    html.H1(children=' ',\n",
    "            style={'padding': '10px'}\n",
    "           ),\n",
    "    \n",
    "\n",
    "    html.Div(\n",
    "        [\n",
    "            html.H3(children='News Classification App',\n",
    "                    style={\"margin-bottom\": \"0px\"}\n",
    "                   ),\n",
    "            html.H6(children='A Machine Learning based app')\n",
    "        ],\n",
    "        style={\n",
    "            'textAlign': 'center',\n",
    "            'color': colors['text'],\n",
    "            'backgroundColor': colors['background']\n",
    "              },\n",
    "        className='banner',\n",
    "            ),\n",
    "    \n",
    "\n",
    "\n",
    "    html.H1(children=' ',\n",
    "            style={'padding': '1px'}),\n",
    "\n",
    "\n",
    "\n",
    "    html.Div(\n",
    "        [\n",
    "            html.Div(\n",
    "                [\n",
    "                    html.H6(children='What does this app do?',\n",
    "                            style={'color':colors['titles']}),\n",
    "                    \n",
    "                    html.Div(\n",
    "                        [dcc.Markdown(children=markdown_text1),],\n",
    "                        style={'font-size': '12px',\n",
    "                               'color': colors['text']}),\n",
    "                                        \n",
    "                    html.Div(\n",
    "                        [\n",
    "                            dcc.Dropdown(\n",
    "                                options=[\n",
    "                                    \n",
    "                                    {'label': 'The Guardian', 'value': 'THG'},\n",
    "                                    {'label': 'Daily Mail', 'value': 'DML'}\n",
    "                                        ],\n",
    "                                value=['EPE'],\n",
    "                                multi=True,\n",
    "                                id='checklist'),\n",
    "                        ],\n",
    "                        style={'font-size': '12px',\n",
    "                               'margin-top': '25px'}),\n",
    "                    \n",
    "                    html.Div([\n",
    "                        html.Button('Scrape', \n",
    "                                    id='submit', \n",
    "                                    type='submit', \n",
    "                                    style={'color': colors['blocks'],\n",
    "                                           'background-color': colors['titles'],\n",
    "                                           'border': 'None'})],\n",
    "                        style={'textAlign': 'center',\n",
    "                               'padding': '20px',\n",
    "                               \"margin-bottom\": \"0px\",\n",
    "                               'color': colors['titles']}),\n",
    "            \n",
    "                    dcc.Loading(id=\"loading-1\", children=[html.Div(id=\"loading-output-1\")], type=\"circle\"),\n",
    "                    \n",
    "                    html.Hr(),\n",
    "                    html.H6(children='Headlines',\n",
    "                            style={'color': colors['titles']}),\n",
    "\n",
    "                    \n",
    "                    html.A(id=\"textarea1a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea1b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea2a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea2b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea3a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea3b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea4a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea4b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea5a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea5b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea6a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea6b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea7a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea7b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea8a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea8b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea9a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea9b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea10a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea10b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea11a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea11b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea12a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea12b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea13a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea13b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea14a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea14b\", style={'color': colors['text'], 'font-size': '11px'}),\n",
    "                    html.A(id=\"textarea15a\", target=\"_blank\", style={'font-size': '12px'}),\n",
    "                    html.P(id=\"textarea15b\", style={'color': colors['text'], 'font-size': '11px'})\n",
    "                                                            \n",
    "                ],\n",
    "                     style={'backgroundColor': colors['blocks'],\n",
    "                            'padding': '20px',\n",
    "                            'border-radius': '5px',\n",
    "                            'box-shadow': '1px 1px 1px #9D9D9D'},\n",
    "                     className='one-half column'),\n",
    "            \n",
    "            html.Div(\n",
    "                [\n",
    "                    html.H6(\"Graphic summary\",\n",
    "                            style={'color': colors['titles']}),\n",
    "\n",
    "                    html.Div([\n",
    "                         dcc.Graph(id='graph1', style={'height': '300px'})\n",
    "                         ],\n",
    "                         style={'backgroundColor': colors['blocks'],\n",
    "                                'padding': '20px'}\n",
    "                    ),\n",
    "                    \n",
    "                    html.Div([\n",
    "                         dcc.Graph(id='graph2', style={'height': '300px'})\n",
    "                         ],\n",
    "                         style={'backgroundColor': colors['blocks'],\n",
    "                                'padding': '20px'}\n",
    "                    )\n",
    "                ],\n",
    "                     style={'backgroundColor': colors['blocks'],\n",
    "                            'padding': '20px',\n",
    "                            'border-radius': '5px',\n",
    "                            'box-shadow': '1px 1px 1px #9D9D9D'},\n",
    "                     className='one-half column')\n",
    "\n",
    "        ],\n",
    "        className=\"row flex-display\",\n",
    "        style={'padding': '20px',\n",
    "               'margin-bottom': '0px'}\n",
    "    ),\n",
    "\n",
    "    html.H1(id='space2', children=' '),\n",
    "        \n",
    "\n",
    "    html.Div(\n",
    "            [dcc.Markdown(children=markdown_text2),],\n",
    "            style={'font-size': '12px',\n",
    "                   'color': colors['text']}),\n",
    "\n",
    "    \n",
    "\n",
    "    html.Div(id='intermediate-value', style={'display': 'none'})\n",
    "    \n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [\n",
    "    Output('intermediate-value', 'children'),\n",
    "    Output('loading-1', 'children')\n",
    "    ],\n",
    "    [Input('submit', 'n_clicks')],\n",
    "    [State('checklist', 'value')])\n",
    "def scrape_and_predict(n_clicks, values):\n",
    "            \n",
    "    df_features = pd.DataFrame()\n",
    "    df_show_info = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    \n",
    "    if 'THG' in values:\n",
    "        df_features = df_features.append(get_news_theguardian()[0])\n",
    "        df_show_info = df_show_info.append(get_news_theguardian()[1])\n",
    "    if 'DML' in values:\n",
    "        df_features = df_features.append(get_news_dailymail()[0])\n",
    "        df_show_info = df_show_info.append(get_news_dailymail()[1])\n",
    "\n",
    "    df_features = df_features.reset_index().drop('index', axis=1)\n",
    "    \n",
    "    \n",
    "    features = create_features_from_df(df_features)\n",
    "    predictions = predict_from_features(features)\n",
    "    df = complete_df(df_show_info, predictions)\n",
    "    \n",
    "    return df.to_json(date_format='iso', orient='split'), ' '\n",
    "\n",
    "@app.callback(\n",
    "    Output('graph1', 'figure'),\n",
    "    [Input('intermediate-value', 'children')])\n",
    "def update_barchart(jsonified_df):\n",
    "    \n",
    "    df = pd.read_json(jsonified_df, orient='split')\n",
    "    df_sum = df.groupby(['Newspaper', 'Prediction']).count()['Article Title']\n",
    "    \n",
    "    if 'The Guardian' in df_sum.index:\n",
    "        \n",
    "        df_sum_thg = df_sum['The Guardian']\n",
    "        x_thg = ['Politics', 'Business', 'Entertainment', 'Sport', 'Tech', 'Other']\n",
    "        y_thg = [[df_sum_thg['politics'] if 'politics' in df_sum_thg.index else 0][0],\n",
    "                [df_sum_thg['business'] if 'business' in df_sum_thg.index else 0][0],\n",
    "                [df_sum_thg['entertainment'] if 'entertainment' in df_sum_thg.index else 0][0],\n",
    "                [df_sum_thg['sport'] if 'sport' in df_sum_thg.index else 0][0],\n",
    "                [df_sum_thg['tech'] if 'tech' in df_sum_thg.index else 0][0],\n",
    "                [df_sum_thg['other'] if 'other' in df_sum_thg.index else 0][0]]   \n",
    "    else:\n",
    "        x_thg = ['Politics', 'Business', 'Entertainment', 'Sport', 'Tech', 'Other']\n",
    "        y_thg = [0,0,0,0,0,0]\n",
    "\n",
    "    if 'Daily Mail' in df_sum.index:\n",
    "    \n",
    "        df_sum_skn = df_sum['Daily Mail']\n",
    "        x_skn = ['Politics', 'Business', 'Entertainment', 'Sport', 'Tech', 'Other']\n",
    "        y_skn = [[df_sum_skn['politics'] if 'politics' in df_sum_skn.index else 0][0],\n",
    "                [df_sum_skn['business'] if 'business' in df_sum_skn.index else 0][0],\n",
    "                [df_sum_skn['entertainment'] if 'entertainment' in df_sum_skn.index else 0][0],\n",
    "                [df_sum_skn['sport'] if 'sport' in df_sum_skn.index else 0][0],\n",
    "                [df_sum_skn['tech'] if 'tech' in df_sum_skn.index else 0][0],\n",
    "                [df_sum_skn['other'] if 'other' in df_sum_skn.index else 0][0]]   \n",
    "\n",
    "    else:\n",
    "        x_skn = ['Politics', 'Business', 'Entertainment', 'Sport', 'Tech', 'Other']\n",
    "        y_skn = [0,0,0,0,0,0]\n",
    "\n",
    "    figure = {\n",
    "        'data': [\n",
    "            \n",
    "            {'x': x_thg, 'y':y_thg, 'type': 'bar', 'name': 'The Guardian', 'marker': {'color': 'rgb(167, 203, 232)'}},\n",
    "            {'x': x_skn, 'y':y_skn, 'type': 'bar', 'name': 'Daily Mail', 'marker': {'color': 'rgb(197, 223, 242)'}}\n",
    "        ],\n",
    "        'layout': {\n",
    "            'title': 'Number of news articles by newspaper',\n",
    "            'plot_bgcolor': colors['graph_background'],\n",
    "            'paper_bgcolor': colors['graph_background'],\n",
    "            'font': {\n",
    "                    'color': colors['text'],\n",
    "                    'size': '10'\n",
    "            },\n",
    "            'barmode': 'stack'\n",
    "            \n",
    "        }   \n",
    "    }\n",
    "\n",
    "    return figure\n",
    "\n",
    "@app.callback(\n",
    "    Output('graph2', 'figure'),\n",
    "    [Input('intermediate-value', 'children')])\n",
    "def update_piechart(jsonified_df):\n",
    "    \n",
    "    df = pd.read_json(jsonified_df, orient='split')\n",
    "    df_sum = df['Prediction'].value_counts()\n",
    "\n",
    "\n",
    "    x = ['Politics', 'Business', 'Entertainment', 'Sport', 'Tech', 'Other']\n",
    "    y = [[df_sum['politics'] if 'politics' in df_sum.index else 0][0],\n",
    "         [df_sum['business'] if 'business' in df_sum.index else 0][0],\n",
    "         [df_sum['entertainment'] if 'entertainment' in df_sum.index else 0][0],\n",
    "         [df_sum['sport'] if 'sport' in df_sum.index else 0][0],\n",
    "         [df_sum['tech'] if 'tech' in df_sum.index else 0][0],\n",
    "         [df_sum['other'] if 'other' in df_sum.index else 0][0]]\n",
    "    \n",
    "\n",
    "    figure = {\n",
    "        'data': [\n",
    "            {'values': y,\n",
    "             'labels': x, \n",
    "             'type': 'pie',\n",
    "             'hole': .4,\n",
    "             'name': '% of news articles',\n",
    "             'marker': {'colors': ['rgb(62, 137, 195)',\n",
    "                                   'rgb(167, 203, 232)',\n",
    "                                   'rgb(197, 223, 242)',\n",
    "                                   'rgb(51, 113, 159)',\n",
    "                                   'rgb(64, 111, 146)',\n",
    "                                   'rgb(31, 84, 132)']},\n",
    "\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        'layout': {\n",
    "            'title': 'News articles by newspaper',\n",
    "            'plot_bgcolor': colors['graph_background'],\n",
    "            'paper_bgcolor': colors['graph_background'],\n",
    "            'font': {\n",
    "                    'color': colors['text'],\n",
    "                    'size': '10'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return figure\n",
    "    \n",
    "@app.callback(\n",
    "    [\n",
    "    Output('textarea1a', 'href'),\n",
    "    Output('textarea1a', 'children'),\n",
    "    Output('textarea1b', 'children'),\n",
    "    Output('textarea2a', 'href'),\n",
    "    Output('textarea2a', 'children'),\n",
    "    Output('textarea2b', 'children'),\n",
    "    Output('textarea3a', 'href'),\n",
    "    Output('textarea3a', 'children'),\n",
    "    Output('textarea3b', 'children'),\n",
    "    Output('textarea4a', 'href'),\n",
    "    Output('textarea4a', 'children'),\n",
    "    Output('textarea4b', 'children'),\n",
    "    Output('textarea5a', 'href'),\n",
    "    Output('textarea5a', 'children'),\n",
    "    Output('textarea5b', 'children'),\n",
    "    Output('textarea6a', 'href'),\n",
    "    Output('textarea6a', 'children'),\n",
    "    Output('textarea6b', 'children'),\n",
    "    Output('textarea7a', 'href'),\n",
    "    Output('textarea7a', 'children'),\n",
    "    Output('textarea7b', 'children'),\n",
    "    Output('textarea8a', 'href'),\n",
    "    Output('textarea8a', 'children'),\n",
    "    Output('textarea8b', 'children'),\n",
    "    Output('textarea9a', 'href'),\n",
    "    Output('textarea9a', 'children'),\n",
    "    Output('textarea9b', 'children'),\n",
    "    Output('textarea10a', 'href'),\n",
    "    Output('textarea10a', 'children'),\n",
    "    Output('textarea10b', 'children'),\n",
    "    Output('textarea11a', 'href'),\n",
    "    Output('textarea11a', 'children'),\n",
    "    Output('textarea11b', 'children'),\n",
    "    Output('textarea12a', 'href'),\n",
    "    Output('textarea12a', 'children'),\n",
    "    Output('textarea12b', 'children'),\n",
    "    Output('textarea13a', 'href'),\n",
    "    Output('textarea13a', 'children'),\n",
    "    Output('textarea13b', 'children'),\n",
    "    Output('textarea14a', 'href'),\n",
    "    Output('textarea14a', 'children'),\n",
    "    Output('textarea14b', 'children'),\n",
    "    Output('textarea15a', 'href'),\n",
    "    Output('textarea15a', 'children'),\n",
    "    Output('textarea15b', 'children')\n",
    "    ],\n",
    "    [Input('intermediate-value', 'children')])\n",
    "def update_textarea1(jsonified_df):\n",
    "    \n",
    "    df = pd.read_json(jsonified_df, orient='split')\n",
    "    \n",
    "    texts = []\n",
    "    links = []\n",
    "    preds_newsp = []\n",
    "    \n",
    "    for article in range(len(df)):\n",
    "        texts.append(df.iloc[article]['Article Title'])\n",
    "        links.append(df.iloc[article]['Article Link'])\n",
    "        preds_newsp.append((df.iloc[article]['Prediction'].capitalize()) + ', ' + (df.iloc[article]['Newspaper']))\n",
    "\n",
    "    while (len(texts) < 16):\n",
    "        texts.append(None)\n",
    "        links.append(None)\n",
    "        preds_newsp.append(None)\n",
    "    \n",
    "    return \\\n",
    "        links[0], texts[0], preds_newsp[0],\\\n",
    "        links[1], texts[1], preds_newsp[1],\\\n",
    "        links[2], texts[2], preds_newsp[2],\\\n",
    "        links[3], texts[3], preds_newsp[3],\\\n",
    "        links[4], texts[4], preds_newsp[4],\\\n",
    "        links[5], texts[5], preds_newsp[5],\\\n",
    "        links[6], texts[6], preds_newsp[6],\\\n",
    "        links[7], texts[7], preds_newsp[7],\\\n",
    "        links[8], texts[8], preds_newsp[8],\\\n",
    "        links[9], texts[9], preds_newsp[9],\\\n",
    "        links[10], texts[10], preds_newsp[10],\\\n",
    "        links[11], texts[11], preds_newsp[11],\\\n",
    "        links[12], texts[12], preds_newsp[12],\\\n",
    "        links[13], texts[13], preds_newsp[13],\\\n",
    "        links[14], texts[14], preds_newsp[14]\n",
    "           \n",
    "    \n",
    "    \n",
    "\n",
    "app.css.append_css({\"external_url\": \"https://codepen.io/chriddyp/pen/bWLwgP.css\"})\n",
    "app.css.append_css({\"external_url\": \"https://codepen.io/chriddyp/pen/brPBPO.css\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
